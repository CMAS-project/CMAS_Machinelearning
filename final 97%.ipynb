{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-09T14:40:36.248063Z",
     "start_time": "2023-06-09T14:40:33.678993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 21:40:34.469496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#tf.keras.utils.img_to_array\n",
    "#tf.keras.utils.load_img\n",
    "from tensorflow.keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "path = 'src/images/images/'\n",
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(path + 'train',\n",
    "                                              target_size=(48, 48),\n",
    "                                              color_mode='grayscale',\n",
    "                                              batch_size= 128,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              shuffle= True)\n",
    "val_gen = val_datagen.flow_from_directory(path+ 'validation',\n",
    "                                          target_size= (48, 48),\n",
    "                                          color_mode= 'grayscale',\n",
    "                                          batch_size= 128,\n",
    "                                          class_mode= 'categorical',\n",
    "                                          shuffle= False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T16:02:59.105741Z",
     "start_time": "2023-05-30T16:02:57.136323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding= 'same', input_shape= (48, 48, 1), activation= 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation= 'relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation= 'relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation= 'relu', padding= 'same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(128, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(256, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(7, activation= 'softmax')\n",
    "])\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T16:02:59.890818Z",
     "start_time": "2023-05-30T16:02:59.825375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('3052023-2302.h5', monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T16:03:01.877034Z",
     "start_time": "2023-05-30T16:03:01.872489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 2.1899 - accuracy: 0.2516WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.25163, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 60s 263ms/step - loss: 2.1899 - accuracy: 0.2516 - val_loss: 1.7074 - val_accuracy: 0.3368\n",
      "Epoch 2/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.6266 - accuracy: 0.3625\n",
      "Epoch 2: accuracy improved from 0.25163 to 0.36246, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.6266 - accuracy: 0.3625\n",
      "Epoch 3/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4939 - accuracy: 0.4187\n",
      "Epoch 3: accuracy improved from 0.36246 to 0.41871, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 1.4939 - accuracy: 0.4187\n",
      "Epoch 4/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3941 - accuracy: 0.4663\n",
      "Epoch 4: accuracy improved from 0.41871 to 0.46628, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.3941 - accuracy: 0.4663\n",
      "Epoch 5/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3191 - accuracy: 0.4960\n",
      "Epoch 5: accuracy improved from 0.46628 to 0.49601, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 1.3191 - accuracy: 0.4960\n",
      "Epoch 6/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2628 - accuracy: 0.5206\n",
      "Epoch 6: accuracy improved from 0.49601 to 0.52061, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.2628 - accuracy: 0.5206\n",
      "Epoch 7/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2224 - accuracy: 0.5350\n",
      "Epoch 7: accuracy improved from 0.52061 to 0.53504, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 1.2224 - accuracy: 0.5350\n",
      "Epoch 8/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.5524\n",
      "Epoch 8: accuracy improved from 0.53504 to 0.55240, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.1788 - accuracy: 0.5524\n",
      "Epoch 9/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1350 - accuracy: 0.5705\n",
      "Epoch 9: accuracy improved from 0.55240 to 0.57052, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.1350 - accuracy: 0.5705\n",
      "Epoch 10/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1034 - accuracy: 0.5822\n",
      "Epoch 10: accuracy improved from 0.57052 to 0.58220, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.1034 - accuracy: 0.5822\n",
      "Epoch 11/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.0729 - accuracy: 0.5956\n",
      "Epoch 11: accuracy improved from 0.58220 to 0.59558, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 1.0729 - accuracy: 0.5956\n",
      "Epoch 12/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.0280 - accuracy: 0.6140\n",
      "Epoch 12: accuracy improved from 0.59558 to 0.61398, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 1.0280 - accuracy: 0.6140\n",
      "Epoch 13/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.6252\n",
      "Epoch 13: accuracy improved from 0.61398 to 0.62524, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.9983 - accuracy: 0.6252\n",
      "Epoch 14/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9641 - accuracy: 0.6382\n",
      "Epoch 14: accuracy improved from 0.62524 to 0.63820, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.9641 - accuracy: 0.6382\n",
      "Epoch 15/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9409 - accuracy: 0.6470\n",
      "Epoch 15: accuracy improved from 0.63820 to 0.64702, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.9409 - accuracy: 0.6470\n",
      "Epoch 16/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9099 - accuracy: 0.6571\n",
      "Epoch 16: accuracy improved from 0.64702 to 0.65706, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.9099 - accuracy: 0.6571\n",
      "Epoch 17/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8676 - accuracy: 0.6754\n",
      "Epoch 17: accuracy improved from 0.65706 to 0.67536, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.8676 - accuracy: 0.6754\n",
      "Epoch 18/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.6842\n",
      "Epoch 18: accuracy improved from 0.67536 to 0.68417, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.8414 - accuracy: 0.6842\n",
      "Epoch 19/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8098 - accuracy: 0.6975\n",
      "Epoch 19: accuracy improved from 0.68417 to 0.69745, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.8098 - accuracy: 0.6975\n",
      "Epoch 20/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7812 - accuracy: 0.7082\n",
      "Epoch 20: accuracy improved from 0.69745 to 0.70819, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.7812 - accuracy: 0.7082\n",
      "Epoch 21/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7700 - accuracy: 0.7130\n",
      "Epoch 21: accuracy improved from 0.70819 to 0.71300, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.7700 - accuracy: 0.7130\n",
      "Epoch 22/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7330 - accuracy: 0.7279\n",
      "Epoch 22: accuracy improved from 0.71300 to 0.72788, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7330 - accuracy: 0.7279\n",
      "Epoch 23/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.7427\n",
      "Epoch 23: accuracy improved from 0.72788 to 0.74272, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.6992 - accuracy: 0.7427\n",
      "Epoch 24/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6729 - accuracy: 0.7507\n",
      "Epoch 24: accuracy improved from 0.74272 to 0.75074, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.6729 - accuracy: 0.7507\n",
      "Epoch 25/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.7618\n",
      "Epoch 25: accuracy improved from 0.75074 to 0.76182, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.6522 - accuracy: 0.7618\n",
      "Epoch 26/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.7644\n",
      "Epoch 26: accuracy improved from 0.76182 to 0.76440, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6368 - accuracy: 0.7644\n",
      "Epoch 27/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.7703\n",
      "Epoch 27: accuracy improved from 0.76440 to 0.77029, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6280 - accuracy: 0.7703\n",
      "Epoch 28/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.7831\n",
      "Epoch 28: accuracy improved from 0.77029 to 0.78312, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.5876 - accuracy: 0.7831\n",
      "Epoch 29/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.7912\n",
      "Epoch 29: accuracy improved from 0.78312 to 0.79124, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.5731 - accuracy: 0.7912\n",
      "Epoch 30/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.8031\n",
      "Epoch 30: accuracy improved from 0.79124 to 0.80309, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.5412 - accuracy: 0.8031\n",
      "Epoch 31/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8094\n",
      "Epoch 31: accuracy improved from 0.80309 to 0.80943, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.5248 - accuracy: 0.8094\n",
      "Epoch 32/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8156\n",
      "Epoch 32: accuracy improved from 0.80943 to 0.81563, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.5062 - accuracy: 0.8156\n",
      "Epoch 33/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.8228\n",
      "Epoch 33: accuracy improved from 0.81563 to 0.82278, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.4845 - accuracy: 0.8228\n",
      "Epoch 34/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.8256\n",
      "Epoch 34: accuracy improved from 0.82278 to 0.82557, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.4782 - accuracy: 0.8256\n",
      "Epoch 35/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8356\n",
      "Epoch 35: accuracy improved from 0.82557 to 0.83557, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.4557 - accuracy: 0.8356\n",
      "Epoch 36/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.8354\n",
      "Epoch 36: accuracy did not improve from 0.83557\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.4493 - accuracy: 0.8354\n",
      "Epoch 37/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8449\n",
      "Epoch 37: accuracy improved from 0.83557 to 0.84494, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.4313 - accuracy: 0.8449\n",
      "Epoch 38/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.8496\n",
      "Epoch 38: accuracy improved from 0.84494 to 0.84965, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.4204 - accuracy: 0.8496\n",
      "Epoch 39/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8558\n",
      "Epoch 39: accuracy improved from 0.84965 to 0.85578, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.4041 - accuracy: 0.8558\n",
      "Epoch 40/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.8595\n",
      "Epoch 40: accuracy improved from 0.85578 to 0.85948, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3929 - accuracy: 0.8595\n",
      "Epoch 41/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8637\n",
      "Epoch 41: accuracy improved from 0.85948 to 0.86366, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3819 - accuracy: 0.8637\n",
      "Epoch 42/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8714\n",
      "Epoch 42: accuracy improved from 0.86366 to 0.87136, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3594 - accuracy: 0.8714\n",
      "Epoch 43/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8689\n",
      "Epoch 43: accuracy did not improve from 0.87136\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3660 - accuracy: 0.8689\n",
      "Epoch 44/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8759\n",
      "Epoch 44: accuracy improved from 0.87136 to 0.87593, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3413 - accuracy: 0.8759\n",
      "Epoch 45/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.8812\n",
      "Epoch 45: accuracy improved from 0.87593 to 0.88123, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3379 - accuracy: 0.8812\n",
      "Epoch 46/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8824\n",
      "Epoch 46: accuracy improved from 0.88123 to 0.88245, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3319 - accuracy: 0.8824\n",
      "Epoch 47/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8893\n",
      "Epoch 47: accuracy improved from 0.88245 to 0.88935, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3190 - accuracy: 0.8893\n",
      "Epoch 48/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8855\n",
      "Epoch 48: accuracy did not improve from 0.88935\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3212 - accuracy: 0.8855\n",
      "Epoch 49/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8924\n",
      "Epoch 49: accuracy improved from 0.88935 to 0.89238, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.3074 - accuracy: 0.8924\n",
      "Epoch 50/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.8944\n",
      "Epoch 50: accuracy improved from 0.89238 to 0.89440, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.3013 - accuracy: 0.8944\n",
      "Epoch 51/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8953\n",
      "Epoch 51: accuracy improved from 0.89440 to 0.89531, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2943 - accuracy: 0.8953\n",
      "Epoch 52/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.8970\n",
      "Epoch 52: accuracy improved from 0.89531 to 0.89701, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2928 - accuracy: 0.8970\n",
      "Epoch 53/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.8986\n",
      "Epoch 53: accuracy improved from 0.89701 to 0.89862, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2868 - accuracy: 0.8986\n",
      "Epoch 54/200\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.8992\n",
      "Epoch 54: accuracy improved from 0.89862 to 0.89921, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2897 - accuracy: 0.8992\n",
      "Epoch 55/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.9034\n",
      "Epoch 55: accuracy improved from 0.89921 to 0.90343, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.2772 - accuracy: 0.9034\n",
      "Epoch 56/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.9076\n",
      "Epoch 56: accuracy improved from 0.90343 to 0.90764, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2639 - accuracy: 0.9076\n",
      "Epoch 57/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.9068\n",
      "Epoch 57: accuracy did not improve from 0.90764\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2663 - accuracy: 0.9068\n",
      "Epoch 58/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9077\n",
      "Epoch 58: accuracy improved from 0.90764 to 0.90771, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2623 - accuracy: 0.9077\n",
      "Epoch 59/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.9126\n",
      "Epoch 59: accuracy improved from 0.90771 to 0.91259, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2556 - accuracy: 0.9126\n",
      "Epoch 60/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9177\n",
      "Epoch 60: accuracy improved from 0.91259 to 0.91772, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2453 - accuracy: 0.9177\n",
      "Epoch 61/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9157\n",
      "Epoch 61: accuracy did not improve from 0.91772\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2454 - accuracy: 0.9157\n",
      "Epoch 62/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9173\n",
      "Epoch 62: accuracy did not improve from 0.91772\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2409 - accuracy: 0.9173\n",
      "Epoch 63/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9181\n",
      "Epoch 63: accuracy improved from 0.91772 to 0.91806, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2362 - accuracy: 0.9181\n",
      "Epoch 64/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.9193\n",
      "Epoch 64: accuracy improved from 0.91806 to 0.91932, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.2358 - accuracy: 0.9193\n",
      "Epoch 65/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9222\n",
      "Epoch 65: accuracy improved from 0.91932 to 0.92225, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2297 - accuracy: 0.9222\n",
      "Epoch 66/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9230\n",
      "Epoch 66: accuracy improved from 0.92225 to 0.92301, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.2227 - accuracy: 0.9230\n",
      "Epoch 67/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9209\n",
      "Epoch 67: accuracy did not improve from 0.92301\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2304 - accuracy: 0.9209\n",
      "Epoch 68/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9264\n",
      "Epoch 68: accuracy improved from 0.92301 to 0.92636, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2151 - accuracy: 0.9264\n",
      "Epoch 69/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9296\n",
      "Epoch 69: accuracy improved from 0.92636 to 0.92956, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2037 - accuracy: 0.9296\n",
      "Epoch 70/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9268\n",
      "Epoch 70: accuracy did not improve from 0.92956\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2189 - accuracy: 0.9268\n",
      "Epoch 71/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9266\n",
      "Epoch 71: accuracy did not improve from 0.92956\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2156 - accuracy: 0.9266\n",
      "Epoch 72/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9315\n",
      "Epoch 72: accuracy improved from 0.92956 to 0.93148, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2046 - accuracy: 0.9315\n",
      "Epoch 73/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9326\n",
      "Epoch 73: accuracy improved from 0.93148 to 0.93256, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1972 - accuracy: 0.9326\n",
      "Epoch 74/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9302\n",
      "Epoch 74: accuracy did not improve from 0.93256\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1980 - accuracy: 0.9302\n",
      "Epoch 75/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.9292\n",
      "Epoch 75: accuracy did not improve from 0.93256\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.2058 - accuracy: 0.9292\n",
      "Epoch 76/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9313\n",
      "Epoch 76: accuracy did not improve from 0.93256\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.2030 - accuracy: 0.9313\n",
      "Epoch 77/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9330\n",
      "Epoch 77: accuracy improved from 0.93256 to 0.93298, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1984 - accuracy: 0.9330\n",
      "Epoch 78/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9311\n",
      "Epoch 78: accuracy did not improve from 0.93298\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.1968 - accuracy: 0.9311\n",
      "Epoch 79/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9358\n",
      "Epoch 79: accuracy improved from 0.93298 to 0.93580, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1912 - accuracy: 0.9358\n",
      "Epoch 80/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9364\n",
      "Epoch 80: accuracy improved from 0.93580 to 0.93643, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1898 - accuracy: 0.9364\n",
      "Epoch 81/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9397\n",
      "Epoch 81: accuracy improved from 0.93643 to 0.93967, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1829 - accuracy: 0.9397\n",
      "Epoch 82/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9376\n",
      "Epoch 82: accuracy did not improve from 0.93967\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.1831 - accuracy: 0.9376\n",
      "Epoch 83/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9378\n",
      "Epoch 83: accuracy did not improve from 0.93967\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1860 - accuracy: 0.9378\n",
      "Epoch 84/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9371\n",
      "Epoch 84: accuracy did not improve from 0.93967\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.1911 - accuracy: 0.9371\n",
      "Epoch 85/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9377\n",
      "Epoch 85: accuracy did not improve from 0.93967\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1836 - accuracy: 0.9377\n",
      "Epoch 86/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9398\n",
      "Epoch 86: accuracy improved from 0.93967 to 0.93978, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1750 - accuracy: 0.9398\n",
      "Epoch 87/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9438\n",
      "Epoch 87: accuracy improved from 0.93978 to 0.94378, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.1671 - accuracy: 0.9438\n",
      "Epoch 88/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9435\n",
      "Epoch 88: accuracy did not improve from 0.94378\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1721 - accuracy: 0.9435\n",
      "Epoch 89/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9407\n",
      "Epoch 89: accuracy did not improve from 0.94378\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1762 - accuracy: 0.9407\n",
      "Epoch 90/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9434\n",
      "Epoch 90: accuracy did not improve from 0.94378\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1737 - accuracy: 0.9434\n",
      "Epoch 91/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9420\n",
      "Epoch 91: accuracy did not improve from 0.94378\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1738 - accuracy: 0.9420\n",
      "Epoch 92/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9496\n",
      "Epoch 92: accuracy improved from 0.94378 to 0.94957, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1560 - accuracy: 0.9496\n",
      "Epoch 93/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9463\n",
      "Epoch 93: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1619 - accuracy: 0.9463\n",
      "Epoch 94/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9457\n",
      "Epoch 94: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1649 - accuracy: 0.9457\n",
      "Epoch 95/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9449\n",
      "Epoch 95: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1659 - accuracy: 0.9449\n",
      "Epoch 96/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9456\n",
      "Epoch 96: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1647 - accuracy: 0.9456\n",
      "Epoch 97/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9475\n",
      "Epoch 97: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1569 - accuracy: 0.9475\n",
      "Epoch 98/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9494\n",
      "Epoch 98: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 55s 242ms/step - loss: 0.1564 - accuracy: 0.9494\n",
      "Epoch 99/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9460\n",
      "Epoch 99: accuracy did not improve from 0.94957\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.1658 - accuracy: 0.9460\n",
      "Epoch 100/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9524\n",
      "Epoch 100: accuracy improved from 0.94957 to 0.95243, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.1463 - accuracy: 0.9524\n",
      "Epoch 101/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9512\n",
      "Epoch 101: accuracy did not improve from 0.95243\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1473 - accuracy: 0.9512\n",
      "Epoch 102/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9486\n",
      "Epoch 102: accuracy did not improve from 0.95243\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1559 - accuracy: 0.9486\n",
      "Epoch 103/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9496\n",
      "Epoch 103: accuracy did not improve from 0.95243\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1492 - accuracy: 0.9496\n",
      "Epoch 104/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9522\n",
      "Epoch 104: accuracy did not improve from 0.95243\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1442 - accuracy: 0.9522\n",
      "Epoch 105/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9466\n",
      "Epoch 105: accuracy did not improve from 0.95243\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1573 - accuracy: 0.9466\n",
      "Epoch 106/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9482\n",
      "Epoch 106: accuracy did not improve from 0.95243\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1554 - accuracy: 0.9482\n",
      "Epoch 107/200\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9529\n",
      "Epoch 107: accuracy improved from 0.95243 to 0.95285, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1416 - accuracy: 0.9528\n",
      "Epoch 108/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9501\n",
      "Epoch 108: accuracy did not improve from 0.95285\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1489 - accuracy: 0.9501\n",
      "Epoch 109/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.9489\n",
      "Epoch 109: accuracy did not improve from 0.95285\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1529 - accuracy: 0.9489\n",
      "Epoch 110/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9508\n",
      "Epoch 110: accuracy did not improve from 0.95285\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1475 - accuracy: 0.9508\n",
      "Epoch 111/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9526\n",
      "Epoch 111: accuracy did not improve from 0.95285\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1449 - accuracy: 0.9526\n",
      "Epoch 112/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9533\n",
      "Epoch 112: accuracy improved from 0.95285 to 0.95330, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1405 - accuracy: 0.9533\n",
      "Epoch 113/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9559\n",
      "Epoch 113: accuracy improved from 0.95330 to 0.95588, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1352 - accuracy: 0.9559\n",
      "Epoch 114/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.9524\n",
      "Epoch 114: accuracy did not improve from 0.95588\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1460 - accuracy: 0.9524\n",
      "Epoch 115/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9535\n",
      "Epoch 115: accuracy did not improve from 0.95588\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1445 - accuracy: 0.9535\n",
      "Epoch 116/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9512\n",
      "Epoch 116: accuracy did not improve from 0.95588\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1446 - accuracy: 0.9512\n",
      "Epoch 117/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9526\n",
      "Epoch 117: accuracy did not improve from 0.95588\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1457 - accuracy: 0.9526\n",
      "Epoch 118/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9527\n",
      "Epoch 118: accuracy did not improve from 0.95588\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1439 - accuracy: 0.9527\n",
      "Epoch 119/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9533\n",
      "Epoch 119: accuracy did not improve from 0.95588\n",
      "225/225 [==============================] - 55s 244ms/step - loss: 0.1397 - accuracy: 0.9533\n",
      "Epoch 120/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9574\n",
      "Epoch 120: accuracy improved from 0.95588 to 0.95738, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1311 - accuracy: 0.9574\n",
      "Epoch 121/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9553\n",
      "Epoch 121: accuracy did not improve from 0.95738\n",
      "225/225 [==============================] - 55s 242ms/step - loss: 0.1368 - accuracy: 0.9553\n",
      "Epoch 122/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9527\n",
      "Epoch 122: accuracy did not improve from 0.95738\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.1433 - accuracy: 0.9527\n",
      "Epoch 123/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9594\n",
      "Epoch 123: accuracy improved from 0.95738 to 0.95940, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 55s 242ms/step - loss: 0.1269 - accuracy: 0.9594\n",
      "Epoch 124/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9556\n",
      "Epoch 124: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 55s 242ms/step - loss: 0.1323 - accuracy: 0.9556\n",
      "Epoch 125/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9581\n",
      "Epoch 125: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.1357 - accuracy: 0.9581\n",
      "Epoch 126/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9560\n",
      "Epoch 126: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 0.1369 - accuracy: 0.9560\n",
      "Epoch 127/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9577\n",
      "Epoch 127: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 57s 254ms/step - loss: 0.1317 - accuracy: 0.9577\n",
      "Epoch 128/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9567\n",
      "Epoch 128: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 60s 268ms/step - loss: 0.1284 - accuracy: 0.9567\n",
      "Epoch 129/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9591\n",
      "Epoch 129: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 57s 252ms/step - loss: 0.1263 - accuracy: 0.9591\n",
      "Epoch 130/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9553\n",
      "Epoch 130: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 57s 252ms/step - loss: 0.1373 - accuracy: 0.9553\n",
      "Epoch 131/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9566\n",
      "Epoch 131: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 57s 252ms/step - loss: 0.1350 - accuracy: 0.9566\n",
      "Epoch 132/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9548\n",
      "Epoch 132: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 60s 266ms/step - loss: 0.1365 - accuracy: 0.9548\n",
      "Epoch 133/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.9585\n",
      "Epoch 133: accuracy did not improve from 0.95940\n",
      "225/225 [==============================] - 57s 255ms/step - loss: 0.1261 - accuracy: 0.9585\n",
      "Epoch 134/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9618\n",
      "Epoch 134: accuracy improved from 0.95940 to 0.96180, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 58s 256ms/step - loss: 0.1187 - accuracy: 0.9618\n",
      "Epoch 135/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9631\n",
      "Epoch 135: accuracy improved from 0.96180 to 0.96313, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1155 - accuracy: 0.9631\n",
      "Epoch 136/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9610\n",
      "Epoch 136: accuracy did not improve from 0.96313\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1230 - accuracy: 0.9610\n",
      "Epoch 137/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9545\n",
      "Epoch 137: accuracy did not improve from 0.96313\n",
      "225/225 [==============================] - 57s 252ms/step - loss: 0.1410 - accuracy: 0.9545\n",
      "Epoch 138/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9577\n",
      "Epoch 138: accuracy did not improve from 0.96313\n",
      "225/225 [==============================] - 57s 254ms/step - loss: 0.1355 - accuracy: 0.9577\n",
      "Epoch 139/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9631\n",
      "Epoch 139: accuracy did not improve from 0.96313\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1118 - accuracy: 0.9631\n",
      "Epoch 140/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9623\n",
      "Epoch 140: accuracy did not improve from 0.96313\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.1133 - accuracy: 0.9623\n",
      "Epoch 141/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9596\n",
      "Epoch 141: accuracy did not improve from 0.96313\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1218 - accuracy: 0.9596\n",
      "Epoch 142/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9641\n",
      "Epoch 142: accuracy improved from 0.96313 to 0.96410, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 56s 251ms/step - loss: 0.1152 - accuracy: 0.9641\n",
      "Epoch 143/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9604\n",
      "Epoch 143: accuracy did not improve from 0.96410\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.1238 - accuracy: 0.9604\n",
      "Epoch 144/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9635\n",
      "Epoch 144: accuracy did not improve from 0.96410\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1149 - accuracy: 0.9635\n",
      "Epoch 145/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9650\n",
      "Epoch 145: accuracy improved from 0.96410 to 0.96501, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 57s 253ms/step - loss: 0.1118 - accuracy: 0.9650\n",
      "Epoch 146/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9643\n",
      "Epoch 146: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.1120 - accuracy: 0.9643\n",
      "Epoch 147/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9626\n",
      "Epoch 147: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.1178 - accuracy: 0.9626\n",
      "Epoch 148/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9612\n",
      "Epoch 148: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 57s 251ms/step - loss: 0.1228 - accuracy: 0.9612\n",
      "Epoch 149/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9643\n",
      "Epoch 149: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1121 - accuracy: 0.9643\n",
      "Epoch 150/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9614\n",
      "Epoch 150: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1200 - accuracy: 0.9614\n",
      "Epoch 151/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9633\n",
      "Epoch 151: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 56s 251ms/step - loss: 0.1148 - accuracy: 0.9633\n",
      "Epoch 152/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9605\n",
      "Epoch 152: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 57s 253ms/step - loss: 0.1184 - accuracy: 0.9605\n",
      "Epoch 153/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9629\n",
      "Epoch 153: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 57s 253ms/step - loss: 0.1165 - accuracy: 0.9629\n",
      "Epoch 154/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9642\n",
      "Epoch 154: accuracy did not improve from 0.96501\n",
      "225/225 [==============================] - 57s 254ms/step - loss: 0.1130 - accuracy: 0.9642\n",
      "Epoch 155/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9663\n",
      "Epoch 155: accuracy improved from 0.96501 to 0.96626, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 59s 263ms/step - loss: 0.1083 - accuracy: 0.9663\n",
      "Epoch 156/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9607\n",
      "Epoch 156: accuracy did not improve from 0.96626\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.1212 - accuracy: 0.9607\n",
      "Epoch 157/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9631\n",
      "Epoch 157: accuracy did not improve from 0.96626\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1168 - accuracy: 0.9631\n",
      "Epoch 158/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9647\n",
      "Epoch 158: accuracy did not improve from 0.96626\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.1090 - accuracy: 0.9647\n",
      "Epoch 159/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9640\n",
      "Epoch 159: accuracy did not improve from 0.96626\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.1144 - accuracy: 0.9640\n",
      "Epoch 160/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9635\n",
      "Epoch 160: accuracy did not improve from 0.96626\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.1113 - accuracy: 0.9635\n",
      "Epoch 161/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9683\n",
      "Epoch 161: accuracy improved from 0.96626 to 0.96832, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 57s 252ms/step - loss: 0.1005 - accuracy: 0.9683\n",
      "Epoch 162/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9666\n",
      "Epoch 162: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.1070 - accuracy: 0.9666\n",
      "Epoch 163/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9666\n",
      "Epoch 163: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 55s 244ms/step - loss: 0.1018 - accuracy: 0.9666\n",
      "Epoch 164/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9648\n",
      "Epoch 164: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.1071 - accuracy: 0.9648\n",
      "Epoch 165/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 165: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 166/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9639\n",
      "Epoch 166: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 59s 262ms/step - loss: 0.1152 - accuracy: 0.9639\n",
      "Epoch 167/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9639\n",
      "Epoch 167: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 55s 242ms/step - loss: 0.1103 - accuracy: 0.9639\n",
      "Epoch 168/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9663\n",
      "Epoch 168: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1036 - accuracy: 0.9663\n",
      "Epoch 169/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9675\n",
      "Epoch 169: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.1010 - accuracy: 0.9675\n",
      "Epoch 170/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9657\n",
      "Epoch 170: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 59s 262ms/step - loss: 0.1066 - accuracy: 0.9657\n",
      "Epoch 171/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9683\n",
      "Epoch 171: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 61s 270ms/step - loss: 0.1008 - accuracy: 0.9683\n",
      "Epoch 172/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9670\n",
      "Epoch 172: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.1085 - accuracy: 0.9670\n",
      "Epoch 173/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9648\n",
      "Epoch 173: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.1093 - accuracy: 0.9648\n",
      "Epoch 174/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9643\n",
      "Epoch 174: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.1142 - accuracy: 0.9643\n",
      "Epoch 175/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9574\n",
      "Epoch 175: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.1363 - accuracy: 0.9574\n",
      "Epoch 176/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9636\n",
      "Epoch 176: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 56s 251ms/step - loss: 0.1190 - accuracy: 0.9636\n",
      "Epoch 177/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9658\n",
      "Epoch 177: accuracy did not improve from 0.96832\n",
      "225/225 [==============================] - 57s 253ms/step - loss: 0.1095 - accuracy: 0.9658\n",
      "Epoch 178/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9686\n",
      "Epoch 178: accuracy improved from 0.96832 to 0.96860, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 57s 255ms/step - loss: 0.0984 - accuracy: 0.9686\n",
      "Epoch 179/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9664\n",
      "Epoch 179: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 57s 253ms/step - loss: 0.1077 - accuracy: 0.9664\n",
      "Epoch 180/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9604\n",
      "Epoch 180: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 57s 254ms/step - loss: 0.1200 - accuracy: 0.9604\n",
      "Epoch 181/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9677\n",
      "Epoch 181: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 57s 252ms/step - loss: 0.0992 - accuracy: 0.9677\n",
      "Epoch 182/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9676\n",
      "Epoch 182: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 58s 259ms/step - loss: 0.1050 - accuracy: 0.9676\n",
      "Epoch 183/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9658\n",
      "Epoch 183: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.1149 - accuracy: 0.9658\n",
      "Epoch 184/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9594\n",
      "Epoch 184: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1345 - accuracy: 0.9594\n",
      "Epoch 185/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9656\n",
      "Epoch 185: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 55s 244ms/step - loss: 0.1101 - accuracy: 0.9656\n",
      "Epoch 186/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9666\n",
      "Epoch 186: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 55s 243ms/step - loss: 0.1083 - accuracy: 0.9666\n",
      "Epoch 187/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9661\n",
      "Epoch 187: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1035 - accuracy: 0.9661\n",
      "Epoch 188/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9673\n",
      "Epoch 188: accuracy did not improve from 0.96860\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.1022 - accuracy: 0.9673\n",
      "Epoch 189/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9704\n",
      "Epoch 189: accuracy improved from 0.96860 to 0.97038, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.0910 - accuracy: 0.9704\n",
      "Epoch 190/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9644\n",
      "Epoch 190: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.1128 - accuracy: 0.9644\n",
      "Epoch 191/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9659\n",
      "Epoch 191: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1121 - accuracy: 0.9659\n",
      "Epoch 192/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9606\n",
      "Epoch 192: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1315 - accuracy: 0.9606\n",
      "Epoch 193/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9682\n",
      "Epoch 193: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 56s 250ms/step - loss: 0.1028 - accuracy: 0.9682\n",
      "Epoch 194/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9695\n",
      "Epoch 194: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.0987 - accuracy: 0.9695\n",
      "Epoch 195/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9633\n",
      "Epoch 195: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 55s 244ms/step - loss: 0.1250 - accuracy: 0.9633\n",
      "Epoch 196/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9677\n",
      "Epoch 196: accuracy did not improve from 0.97038\n",
      "225/225 [==============================] - 55s 246ms/step - loss: 0.1001 - accuracy: 0.9677\n",
      "Epoch 197/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9715\n",
      "Epoch 197: accuracy improved from 0.97038 to 0.97153, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 55s 243ms/step - loss: 0.0894 - accuracy: 0.9715\n",
      "Epoch 198/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9739\n",
      "Epoch 198: accuracy improved from 0.97153 to 0.97390, saving model to 3052023-2302.h5\n",
      "225/225 [==============================] - 55s 244ms/step - loss: 0.0885 - accuracy: 0.9739\n",
      "Epoch 199/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9727\n",
      "Epoch 199: accuracy did not improve from 0.97390\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.0898 - accuracy: 0.9727\n",
      "Epoch 200/200\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9728\n",
      "Epoch 200: accuracy did not improve from 0.97390\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.0914 - accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(train_gen,\n",
    "                             steps_per_epoch= 225,\n",
    "                             epochs= 200,\n",
    "                             validation_data= val_gen,\n",
    "                             validation_steps= 100,\n",
    "                   callbacks= callbacks_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T19:06:47.554078Z",
     "start_time": "2023-05-30T16:03:06.117893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# serialize model structure to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"3052023-2302\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T19:15:41.023813Z",
     "start_time": "2023-05-30T19:15:41.016830Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./model')\n",
    "model.save('./model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T19:15:07.109085Z",
     "start_time": "2023-05-30T19:15:06.032382Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "#model.save('latestmodel.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T00:31:31.831728Z",
     "start_time": "2023-05-27T00:31:31.779721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('FINAL 97%/3052023-2302.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T14:42:48.876928Z",
     "start_time": "2023-06-09T14:42:48.673108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T14:49:17.860639Z",
     "start_time": "2023-06-09T14:49:17.857044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "tf.Tensor(\n",
      "[0.11530168 0.11493786 0.11493971 0.30915797 0.11577818 0.11494576\n",
      " 0.11493883], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputgajelas= 'src/images/validation/happy/366.jpg'\n",
    "img = load_img(inputgajelas, target_size= (48, 48), grayscale= True)\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T14:48:47.218640Z",
     "start_time": "2023-06-09T14:48:47.157841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T14:49:04.207664Z",
     "start_time": "2023-06-09T14:49:04.204735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
